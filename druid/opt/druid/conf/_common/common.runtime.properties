# Extensions
druid.extensions.directory=/opt/druid/extensions
druid.extensions.hadoopDependenciesDir=/opt/druid/hadoop-dependencies
#druid.extensions.loadList=["druid-kafka-indexing-service", "druid-hdfs-storage", "druid-histogram", "druid-datasketches", "druid-lookups-cached-global", "mysql-metadata-storage"]
druid.extensions.loadList=["druid-kafka-indexing-service", "druid-hdfs-storage", "druid-histogram", "druid-datasketches", "druid-lookups-cached-global", "postgresql-metadata-storage"]
druid.extensions.searchCurrentClassloader=true
druid.extensions.addExtensionsToHadoopContainer=false

# Modules
druid.modules.excludeList=[]

# Zookeeper
druid.zk.service.host=zookeeper01:2181,zookeeper02:2181,zookeeper03:2181
druid.zk.paths.base=/druid
druid.zk.service.sessionTimeoutMs=30000
druid.zk.service.compress=true
druid.zk.service.acl=false

# Exhibitor
#druid.exhibitor.service.hosts=['smartsentinel-02']
#druid.exhibitor.service.port=8080
#druid.exhibitor.service.restUriPath=/exhibitor/v1/cluster/list
#druid.exhibitor.service.useSsl=false
#druid.exhibitor.service.pollingMs=10000
#Note that druid.zk.service.host is used as a backup in case an Exhibitor instance can't be contacted and therefore should still be set.

# Logging
druid.startup.logging.logProperties=true
druid.request.logging.type=noop
druid.monitoring.emissionPeriod=PT1m
#druid.monitoring.monitors=["com.metamx.metrics.SysMonitor","com.metamx.metrics.JvmMonitor"]
druid.emitter=noop
druid.emitter.logging.loggerClass=LoggingEmitter
druid.emitter.logging.logLevel=info
druid.emitter.http.flushMillis=60000
druid.emitter.http.flushCount=500
druid.emitter.http.maxBatchSize=5191680
druid.emitter.http.batchQueueSizeLimit=50
druid.emitter.http.minHttpTimeoutMillis=0

# Metadata Storage
#druid.metadata.storage.type=mysql
druid.metadata.storage.type=postgresql
druid.metadata.storage.connector.connectURI=jdbc:postgresql://postgresql01/druid
druid.metadata.storage.connector.user=druid
druid.metadata.storage.connector.password=w4nk1ng
druid.metadata.storage.connector.createTables=true
druid.metadata.storage.tables.base=druid
druid.metadata.storage.tables.segments=druid_segments
druid.metadata.storage.tables.rules=druid_rules
druid.metadata.storage.tables.config=druid_config
druid.metadata.storage.tables.tasks=druid_tasks
druid.metadata.storage.tables.taskLog=druid_taskLog
druid.metadata.storage.tables.taskLock=druid_taskLock
druid.metadata.storage.tables.supervisors=druid_supervisors
druid.metadata.storage.tables.audit=druid_audit

# Deep Storage
druid.storage.type=hdfs
druid.storage.storageDirectory=hdfs://hdfsnamenode01:54310/druid/localStorage

# Caching historical/broker. Sets either in broker or historical if you want to used cache
# groupBy v2 only supports caching on historical nodes
druid.cache.type=local
druid.cache.sizeInBytes=0
druid.cache.initialSize=500000
druid.cache.logEvictionCount=0

# Indexing Service Discovery
druid.selectors.indexing.serviceName=overlord

# Coordinator Discovery
druid.selectors.coordinator.serviceName=coordinator

# Announcing Segments
druid.announcer.segmentsPerNode=50
druid.announcer.maxBytesPerNode=524288
druid.announcer.skipDimensionsAndMetrics=false
druid.announcer.skipLoadSpec=false

# JavaScript
druid.javascript.enabled=true

# Double Column storage
druid.indexing.doubleStorage=float
