druid.host=druidbroker01
druid.port=8082
#druid.plaintextPort=8082
druid.service=broker

# Query Configs
druid.broker.balancer.type=random
druid.broker.select.tier=highestPriority
druid.server.http.numThreads=36
druid.server.http.maxIdleTime=PT5m
druid.server.http.defaultQueryTimeout=300000
druid.broker.http.numConnections=20
druid.broker.http.compressionCodec=gzip
druid.broker.http.readTimeout=PT9M
druid.query.search.maxSearchLimit=1000
druid.query.segmentMetadata.defaultHistory=P1W
druid.query.segmentMetadata.defaultAnalysisTypes=["cardinality", "interval", "minmax"]
#druid.query.groupBy.maxIntermediateRows=
#druid.query.groupBy.maxResults=

# TODO
# groupBy server configuration http://druid.io/docs/latest/querying/groupbyquery.html#server-configuration
# SQL server configuration. http://druid.io/docs/latest/querying/sql.html#configuration
#druid.query.groupBy.defaultStrategy=

# Retry Policy
druid.broker.retryPolicy.numTries=1

# Processing threads and buffers. Antes 450MB (471859200)
druid.processing.buffer.sizeBytes=471859200
druid.processing.numMergeBuffers=1
druid.processing.numThreads=7
druid.processing.columnCache.sizeBytes=0
druid.processing.fifo=false
druid.processing.tmpDir=/opt/druid/tmp/broker


# Query cache
# Local cache resides in JVM heap memory, so if you enable it, make sure you increase heap size accordingly.
# Enabling caching on the broker can yield faster results than if query caches were enabled on Historicals for small clusters.
#  (< 20 servers).
druid.broker.cache.useCache=true
druid.broker.cache.populateCache=true
druid.broker.cache.unCacheable=[]
#druid.broker.cache.unCacheable=["groupBy", "select"]

# Caching historical/broker. Sets either in broker or historical if you want to used cache
# groupBy v2 only supports caching on historical nodes
druid.cache.type=local
druid.cache.sizeInBytes=0
druid.cache.initialSize=500000
druid.cache.logEvictionCount=0


# Others

